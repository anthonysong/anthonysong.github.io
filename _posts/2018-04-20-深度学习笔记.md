---
layout: post
title: 深度学习笔记
date: 2018-04-20
categories: deep_learning
tags: [deep_learning,keras,Tensorflow]
description: keras深度学习框架
---
## 概述
最近在做一个基于深度学习的数据库审计系统，需要利用深度学习对SQL请求进行判断，是否为SQL注入语句。我的思路是用常用SQL注入语句作为训练集，用生成的模型去判断SQL注入。由于之前没有了解过深度学习，于是在这里分享一下我的学习思路，也是对自己学习过程的一个复盘。

## 环境配置
我采用的框架是Keras，一个可以支持多种深度学习后端的API框架，包括`Tensorflow` `Theano`以及`CNTK`。[keras中文文档](http://keras-cn.readthedocs.io/en/latest/)是一个很详细的文档，他里面包括了安装到基本使用的全部信息，可以用这个来入门。

## 序贯模型
Sequential即序贯模型，是多个网络层的线性堆叠。

## 构建第一个深度学习网络
```python
from keras.models import Sequential
from keras.layers import Dense,Activation

#可以传递一个list来完成网络的定义
model = Sequential([
Dense(32, units=784),
Activation('relu'),
Dense(10),
Activation('softmax'),
])

#也可以通过.add()方法
model = Sequential()
model.add(Dense(32, input_shape=(784,)))
model.add(Activation('relu'))

#可以同时在网络层中定义激活函数
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=64))

#定义优化器，SGD即随机梯度下降（Stochastic Gradient Descent）随机选取样本量进行梯度计算。优点是每次选取部分样本进行计算，学习速度很快，但是会产生波动，使收敛速度变慢。
sgd = SGD(lr=0.001, momentum=0.9)

#进行编译，定义损失函数，优化器和指标
model.compile(loss='mse',
              optimizer=sgd,
              metrics=['accuracy'])

#fit进行训练，返回History对象，其History.history属性记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况
#epochs即训练轮数
#batch_size进行梯度下降的批的大小。较大的值会使每个epoch迭代的次数变少，需要更长时间达到相同精度，对参数的修正也更缓慢。较小的批大小，会使收敛方向更不稳定，更不易收敛
history=model.fit(x, y,epochs=5,batch_size=16)

#保存训练模型
model.save(model_name)
```

## 网络层
### Dense
稠密层、全连接层
### Dropout
Dropout在训练时，按照指定的比率，对数据进行弃用，不参与本次的更新，主要目的是为了防止过拟合。

## Activation
### reLu
线性整流函数（Rectified Linear Unit, ReLU），模仿人的神经对信息处理比较稀疏，同一时间内只有部分神经元活跃。
稀疏激活性可以有效地提取数据特征，快速进行梯度下降。更有效率地梯度下降以及反向传播，避免了梯度爆炸和梯度消失。同时计算速度快，加速了网络的训练。

### softMax
用于分类神经网络的输出，按概率取最大值。输出结果的概率分布，满足输入的预测。
## Optimizer
### SGD
随机梯度下降，随机选取样本大小进行梯度计算，在收敛时间和准确性之间做平衡。


## 损失函数
### mse
均方差为常用的损失函数，计算样本和平均值方差的期望。

## 总结
keras是一个高度封装的深度学习框架，同时又具有很强的配置能力，方便学习深度学习，搭建自己的模型。
